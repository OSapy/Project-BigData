{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de Données Massives\n",
    "\n",
    "# Projet Partie n°1 \n",
    "\n",
    "### Binôme : Sapy Oscar & Berthillon Mickaël"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 : Collecte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the API endpoint and your access key\n",
    "url = \"https://api.pexels.com/v1/search\"\n",
    "access_key = \"MgxBjp4CnSFtTvWe3SeHtkTGp5oUOBWVG5S0PYZAd37hV3T3h2yY4PHp\"\n",
    "\n",
    "# Define the headers with your access key\n",
    "headers = {\n",
    "    \"Authorization\": access_key\n",
    "}\n",
    "\n",
    "# Define the path to the images folder\n",
    "path = \"./images\"\n",
    "\n",
    "# Define the number of images to download\n",
    "num_images = 5\n",
    "\n",
    "# Define the query parameters\n",
    "query_params = {\n",
    "    \"query\": \"random\", \n",
    "    \"per_page\": num_images\n",
    "}\n",
    "\n",
    "# Create the images folder if it doesn't exist\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Send the API request and download the images\n",
    "response = requests.get(url, headers=headers, params=query_params)\n",
    "json = response.json()\n",
    "for i in range(num_images):\n",
    "    image_url = json[\"photos\"][i][\"src\"][\"original\"]\n",
    "    image_id = json[\"photos\"][i][\"id\"]\n",
    "    image_extension = \".jpg\" # change extension as per your requirement\n",
    "    image_filename = f\"{image_id}{image_extension}\"\n",
    "    image_path = os.path.join(path, image_filename)\n",
    "\n",
    "    # Download the image and save it to the images folder\n",
    "    response = requests.get(image_url)\n",
    "    with open(image_path, \"wb\") as f:\n",
    "        f.write(response.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 : Etiquetage et annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from PIL.TiffImagePlugin import IFDRational\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, bytes):\n",
    "            try:\n",
    "                return obj.decode('utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                return obj.decode('utf-8', 'replace')\n",
    "        elif isinstance(obj, IFDRational):\n",
    "            return float(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "# Path to the folder containing pictures\n",
    "path_to_folder = './images'\n",
    "\n",
    "# Create the metadata folder if it doesn't exist\n",
    "if not os.path.exists('metadata'):\n",
    "    os.mkdir('metadata')\n",
    "\n",
    "# Loop over all pictures in the folder\n",
    "for filename in os.listdir(path_to_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # Open the image and get the EXIF data\n",
    "        image = Image.open(os.path.join(path_to_folder, filename))\n",
    "        exifdata = image.getexif()\n",
    "\n",
    "        # Create a dictionary to store the metadata for this image\n",
    "        metadata = {}\n",
    "\n",
    "        # Loop over all EXIF tags and add them to the metadata dictionary\n",
    "        for tag_id, value in exifdata.items():\n",
    "            tag = TAGS.get(tag_id, tag_id)\n",
    "            metadata[tag] = value\n",
    "\n",
    "        # Write the metadata dictionary to a JSON file in the metadata folder\n",
    "        json_filename = os.path.splitext(filename)[0] + '.json'\n",
    "        with open(os.path.join('metadata', json_filename), 'w') as f:\n",
    "            json.dump(metadata, f, cls=MyEncoder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 : Analyse de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mick/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mick/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import cv2\n",
    "from colorthief import ColorThief\n",
    "import pytesseract\n",
    "from imageai.Detection import ObjectDetection\n",
    "\"\"\"\n",
    "# Download the YOLOv3 PyTorch model\n",
    "url = \"https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"pretrained-yolov3.pt\", \"wb\") as f:  \n",
    "    f.write(response.content)\n",
    "\n",
    "image_path = \"./images\"\n",
    "\n",
    "# Initialize the ViT feature extractor and model\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Initialize ImageAI object detection model\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"pretrained-yolov3.pt\")\n",
    "detector.loadModel()\"\"\"\n",
    "\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Initialize torchvision object detection model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "image_path = \"./images\"\n",
    "\n",
    "# Function to get image metadata\n",
    "def get_image_metadata(image_path):\n",
    "    metadata = {}\n",
    "\n",
    "    # Read the image using PIL and OpenCV\n",
    "    pil_image = Image.open(image_path)\n",
    "    cv_image = cv2.imread(image_path)\n",
    "\n",
    "    # Get dominant color and color palette\n",
    "    color_thief = ColorThief(image_path)\n",
    "    dominant_color = color_thief.get_color(quality=1)\n",
    "    color_palette = color_thief.get_palette(color_count=5)\n",
    "\n",
    "    # Get orientation\n",
    "    exif_data = pil_image._getexif()\n",
    "    orientation = exif_data[274] if exif_data and 274 in exif_data else \"unknown\"\n",
    "\n",
    "\n",
    "    # Get number of faces\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=3)\n",
    "    num_faces = len(faces)\n",
    "\n",
    "    # Get text\n",
    "    pil_image_rgb = pil_image.convert('RGB')\n",
    "    text = pytesseract.image_to_string(pil_image_rgb)\n",
    "\n",
    "    # Get objects\n",
    "    transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor()])\n",
    "    img = transform(Image.open(image_path))\n",
    "    img = img.unsqueeze(0)\n",
    "    detections = model(img)\n",
    "\n",
    "    objects = []\n",
    "    for label, score in zip(detections[0][\"labels\"], detections[0][\"scores\"]):\n",
    "        if score > 0.5:\n",
    "            objects.append(label.item())\n",
    "\n",
    "\n",
    "    # Build metadata dictionary\n",
    "    metadata = {\n",
    "        \"orientation\": orientation,\n",
    "        \"dominant_color\": dominant_color,\n",
    "        \"color_palette\": color_palette,\n",
    "        \"num_faces\": num_faces,\n",
    "        \"text\": text,\n",
    "        \"objects\": objects,\n",
    "    }\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Loop over all pictures in the folder\n",
    "for filename in os.listdir(path_to_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "        # Get the image metadata\n",
    "        image_path = os.path.join(path_to_folder, filename)\n",
    "        metadata = get_image_metadata(image_path)\n",
    "\n",
    "        # Write the metadata dictionary to a JSON file in the metadata folder\n",
    "        with open(os.path.join(\"metadata\", os.path.splitext(filename)[0] + \".json\"), \"w\") as f:\n",
    "            json.dump(metadata, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 : Visualisation de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image image1 with metadata file 1000366.jpg found and added to liked images...\n",
      "Image image2 with metadata file  not found. Skipping...\n",
      "Image image3 with metadata file  not found. Skipping...\n",
      "Image image4 with metadata file  not found. Skipping...\n",
      "Image image5 with metadata file  not found. Skipping...\n",
      "Image image6 with metadata file  not found. Skipping...\n",
      "Image image7 with metadata file  not found. Skipping...\n",
      "Image image8 with metadata file  not found. Skipping...\n",
      "Image image9 with metadata file  not found. Skipping...\n",
      "Image image10 with metadata file  not found. Skipping...\n",
      "Image image11 with metadata file  not found. Skipping...\n",
      "Image image12 with metadata file  not found. Skipping...\n",
      "Image image13 with metadata file  not found. Skipping...\n",
      "['image1']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the user's preferences from the preferences.json file\n",
    "with open(\"preferences.json\", \"r\") as f:\n",
    "    preferences = json.load(f)\n",
    "\n",
    "liked_images = []\n",
    "\n",
    "# Verify if the image metadata file exists and add it to the liked_images list\n",
    "for key, value in preferences.items():\n",
    "    if value and os.path.exists(os.path.join(\"images\", value)):\n",
    "        liked_images.append(key)  # Append the key (image identifier) instead of the value (filename)\n",
    "        print(f\"Image {key} with metadata file {value} found and added to liked images...\")\n",
    "    else:\n",
    "        print(f\"Image {key} with metadata file {value} not found. Skipping...\")\n",
    "\n",
    "print(liked_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('orientation', 'unknown'), ('dominant_color', [194, 196, 190]), ('color_palette', [[194, 196, 190], [59, 73, 80], [147, 137, 122], [116, 82, 84], [127, 120, 63]]), ('num_faces', 18), ('text', ' \\n\\x0c'), ('objects', [])]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Read the user's preferences from the preferences.json file\n",
    "with open(\"preferences.json\", \"r\") as f:\n",
    "    preferences = json.load(f)\n",
    "\n",
    "liked_images = []\n",
    "\n",
    "# Verify if the image metadata file exists and add it to the liked_images list\n",
    "for key, value in preferences.items():\n",
    "    if value and os.path.exists(os.path.join(\"metadata\", os.path.splitext(value)[0] + \".json\")):\n",
    "        liked_images.append(value)\n",
    "\n",
    "preferred_tags = []\n",
    "\n",
    "# Loop through the liked_images list and get the tags from the metadata files\n",
    "for image in liked_images:\n",
    "    metadata_file = os.path.join(\"metadata\", os.path.splitext(image)[0] + \".json\")\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Add the tags to the preferred_tags array\n",
    "    for tag, value in metadata.items():\n",
    "        preferred_tags.append((tag, value))\n",
    "\n",
    "print(preferred_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4194850': 2, '4226881': 2, '1000366': 6, '3737018': 2, '3844788': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Read the user's preferences from the preferences.json file\n",
    "with open(\"preferences.json\", \"r\") as f:\n",
    "    preferences = json.load(f)\n",
    "\n",
    "liked_images = []\n",
    "\n",
    "# Verify if the image metadata file exists and add it to the liked_images list\n",
    "for key, value in preferences.items():\n",
    "    if value and os.path.exists(os.path.join(\"images\", value)):\n",
    "        liked_images.append(key)\n",
    "\n",
    "liked_images_filenames = [preferences[key] for key in liked_images]\n",
    "\n",
    "preferred_tags = []\n",
    "for image in liked_images:\n",
    "    with open(os.path.join(\"metadata\", preferences[image].split('.')[0] + \".json\"), \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    for key, value in metadata.items():\n",
    "        preferred_tags.append((key, value))\n",
    "\n",
    "similarity_scores = {}\n",
    "\n",
    "# Loop through all metadata files in the metadata folder\n",
    "for metadata_file in os.listdir(\"metadata\"):\n",
    "    image_filename = os.path.splitext(metadata_file)[0] + \".jpg\"\n",
    "    \n",
    "    # Check if the current image is in the liked_images_filenames list\n",
    "    if image_filename not in liked_images_filenames:\n",
    "        with open(os.path.join(\"metadata\", metadata_file), \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "        # Calculate the similarity score\n",
    "        similarity_score = 0\n",
    "        for key, value in preferred_tags:\n",
    "            if key in metadata and metadata[key] == value:\n",
    "                similarity_score += 1\n",
    "\n",
    "        # Add the similarity score to the dictionary\n",
    "        if similarity_score > 0:\n",
    "            similarity_scores[image_filename] = similarity_score\n",
    "\n",
    "print(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
